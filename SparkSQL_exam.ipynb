{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark= SparkSession.builder.appName(\"trip\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='c://Users//apfhd//SparkExam//data//fhvhv_tripdata_2020-03.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   null|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   null|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   null|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 컬럼정보 넣기 (header = True) \n",
    "datas=spark.read.csv(f'file:///{directory}',header=True)\n",
    "datas.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL 사용 할 수 있게 임시 view등록\n",
    "datas.createOrReplaceTempView(\"mobility_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   null|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   null|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   null|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select * from mobility_data limit 5\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|pickup_date| trips|\n",
      "+-----------+------+\n",
      "| 2020-03-02|648986|\n",
      "| 2020-03-01|784246|\n",
      "| 2020-03-03|697880|\n",
      "| 2020-03-04|707879|\n",
      "| 2020-03-05|731165|\n",
      "+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 승차 년 월 일 별로 카운트 세기\n",
    "query= '''\n",
    "select split(pickup_datetime,' ')[0] as pickup_date, count(*) as trips\n",
    "from mobility_data\n",
    "group by pickup_date\n",
    "'''\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 좀 더 좋은 방안\n",
    "```\n",
    "query= '''\n",
    "select split(pickup_datetime,' ')[0] as pickup_date, count(*) as trips\n",
    "from mobility_data\n",
    "group by pickup_date\n",
    "'''\n",
    "```\n",
    "-> 이 내용을 subquery로 활용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|pickup_date| trips|\n",
      "+-----------+------+\n",
      "| 2020-03-02|648986|\n",
      "| 2020-03-01|784246|\n",
      "| 2020-03-03|697880|\n",
      "| 2020-03-04|707879|\n",
      "| 2020-03-05|731165|\n",
      "+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 좀 더 나은 방법\n",
    "query= \"\"\"\n",
    "select pickup_date, count(*) as trips\n",
    "\n",
    "from(select split(pickup_datetime,' ')[0] as pickup_date\n",
    "from mobility_data)\n",
    "\n",
    "group by pickup_date\n",
    "\"\"\"\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['pickup_date], ['pickup_date, 'count(1) AS trips#442]\n",
      "+- 'SubqueryAlias __auto_generated_subquery_name\n",
      "   +- 'Project ['split('pickup_datetime,  )[0] AS pickup_date#441]\n",
      "      +- 'UnresolvedRelation [mobility_data], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "pickup_date: string, trips: bigint\n",
      "Aggregate [pickup_date#441], [pickup_date#441, count(1) AS trips#442L]\n",
      "+- SubqueryAlias __auto_generated_subquery_name\n",
      "   +- Project [split(pickup_datetime#180,  , -1)[0] AS pickup_date#441]\n",
      "      +- SubqueryAlias mobility_data\n",
      "         +- View (`mobility_data`, [hvfhs_license_num#178,dispatching_base_num#179,pickup_datetime#180,dropoff_datetime#181,PULocationID#182,DOLocationID#183,SR_Flag#184])\n",
      "            +- Relation [hvfhs_license_num#178,dispatching_base_num#179,pickup_datetime#180,dropoff_datetime#181,PULocationID#182,DOLocationID#183,SR_Flag#184] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [pickup_date#441], [pickup_date#441, count(1) AS trips#442L]\n",
      "+- Project [split(pickup_datetime#180,  , -1)[0] AS pickup_date#441]\n",
      "   +- Relation [hvfhs_license_num#178,dispatching_base_num#179,pickup_datetime#180,dropoff_datetime#181,PULocationID#182,DOLocationID#183,SR_Flag#184] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[pickup_date#441], functions=[count(1)], output=[pickup_date#441, trips#442L])\n",
      "   +- Exchange hashpartitioning(pickup_date#441, 200), ENSURE_REQUIREMENTS, [id=#577]\n",
      "      +- HashAggregate(keys=[pickup_date#441], functions=[partial_count(1)], output=[pickup_date#441, count#447L])\n",
      "         +- Project [split(pickup_datetime#180,  , -1)[0] AS pickup_date#441]\n",
      "            +- FileScan csv [pickup_datetime#180] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/c:/Users/apfhd/SparkExam/data/fhvhv_tripdata_2020-03.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<pickup_datetime:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 계획 살펴보기\n",
    "spark.sql(query).explain(True)\n",
    "# Parsed Logical Plan -> 작성 한 쿼리를 분석하는 단계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_file = \"c://Users//apfhd//SparkExam//data//taxi+_zone_lookup.csv\"\n",
    "zone_data = spark.read.csv(f\"file:///{zone_file}\", inferSchema=True, header=True)\n",
    "zone_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_data.createOrReplaceTempView('zone_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|      borough|  trips|\n",
      "+-------------+-------+\n",
      "|       Queens|2437383|\n",
      "|          EWR|    362|\n",
      "|      Unknown|    845|\n",
      "|     Brooklyn|3735764|\n",
      "|Staten Island| 178818|\n",
      "|    Manhattan|4953140|\n",
      "|        Bronx|2086592|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "\n",
    "select borough, count(*) as trips\n",
    "\n",
    "from(select zone_data.Borough as borough\n",
    "    from mobility_data\n",
    "    join zone_data on mobility_data.PULocationID = zone_data.LocationID)\n",
    "    \n",
    "group by borough\n",
    "\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|      borough|  trips|\n",
      "+-------------+-------+\n",
      "|       Queens|1863688|\n",
      "|      Unknown|    548|\n",
      "|     Brooklyn|2779375|\n",
      "|Staten Island| 148199|\n",
      "|    Manhattan|3270666|\n",
      "|        Bronx|1774283|\n",
      "|          EWR|      4|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 지역별 운영 횟수 - 그중에서도 HV003에 대한\n",
    "query = \"\"\"\n",
    "\n",
    "select borough, count(*) as trips\n",
    "\n",
    "from (select zone_data.Borough as borough\n",
    "      from mobility_data\n",
    "      join zone_data on mobility_data.PULocationID = zone_data.LocationID\n",
    "      where mobility_data.hvfhs_license_num='HV0003'\n",
    "      )\n",
    "\n",
    "group by borough\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
