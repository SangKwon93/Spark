{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"operation_example \")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면',\n",
       " '짬뽕',\n",
       " '마라탕',\n",
       " '떡볶이',\n",
       " '쌀국수',\n",
       " '짬뽕',\n",
       " '짜장면',\n",
       " '짜장면',\n",
       " '짬뽕',\n",
       " '마라탕',\n",
       " '라면',\n",
       " '라면',\n",
       " '우동',\n",
       " '쌀국수']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foods = sc.parallelize([\n",
    "    \"짜장면\",\"짬뽕\",\"마라탕\",\n",
    "    \"떡볶이\",\"쌀국수\",\"짬뽕\",\n",
    "    \"짜장면\",\"짜장면\",\"짬뽕\",\n",
    "    \"마라탕\",\"라면\",\"라면\",\n",
    "    \"우동\",\"쌀국수\"\n",
    "    \n",
    "])\n",
    "foods.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그룹핑하는건 좋은데 후처리를 for 문으로 처리를 하면 효과가 좋지않다.\n",
    "\n",
    "- 그룹핑 하는거 괜찮다. 하지만 후처리를 for문으로 하는 것은 효과가 좋지 않다.  \n",
    "- `for문 쓰는순간 병렬처리 x`  \n",
    "    - 파티션 내에서 변환수행하는 것이 아니라 드라이버 프로그램에서 하겠다.  \n",
    "    - `즉, worker node 에서 일어나는 작업이 아니라  master node에서 작업을 하는거 -> 속도 느려진다.`  \n",
    "- groupby 하고 key는 그대로 냅두고 value에 대한 처리를 따로 할 수 있도록 함수를 만들곤 한다.  \n",
    "    - 일반적으로 groupby랑 같이 사용되는 mapValues이다.  \n",
    "==> 값 처리를 모조리 워커에서 할수있게 해준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foodsGroup = foods.groupBy(lambda x : x) \n",
    "foodsGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜장면', <pyspark.resultiterable.ResultIterable at 0x2b2bd06af70>),\n",
       " ('짬뽕', <pyspark.resultiterable.ResultIterable at 0x2b2bd42ca90>),\n",
       " ('마라탕', <pyspark.resultiterable.ResultIterable at 0x2b2bd42caf0>),\n",
       " ('떡볶이', <pyspark.resultiterable.ResultIterable at 0x2b2bd42cb50>),\n",
       " ('쌀국수', <pyspark.resultiterable.ResultIterable at 0x2b2bd42cbb0>),\n",
       " ('라면', <pyspark.resultiterable.ResultIterable at 0x2b2bd42cc10>),\n",
       " ('우동', <pyspark.resultiterable.ResultIterable at 0x2b2bd42cc70>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = foodsGroup.collect()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 비추천 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('짜장면', 3)\n",
      "('짬뽕', 3)\n",
      "('마라탕', 2)\n",
      "('떡볶이', 1)\n",
      "('쌀국수', 2)\n",
      "('라면', 2)\n",
      "('우동', 1)\n"
     ]
    }
   ],
   "source": [
    "# (직렬처리) 추천하지 않는다.\n",
    "for k,v in result:\n",
    "    lst = (k,len(v))\n",
    "    print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 추천 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜장면', 1),\n",
       " ('짬뽕', 1),\n",
       " ('마라탕', 1),\n",
       " ('떡볶이', 1),\n",
       " ('쌀국수', 1),\n",
       " ('라면', 1),\n",
       " ('우동', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (병렬처리)이 방법이 더 효율적이다.\n",
    "foodsGroup.groupByKey().mapValues(len).collect()\n",
    "# 함수 만들고 mapvalues로 돌리는 것이 훨씬 더 유리 => master가 일하지 않고 woker가 일해 (transformation 작업)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜장면', 1),\n",
       " ('짬뽕', 1),\n",
       " ('마라탕', 1),\n",
       " ('떡볶이', 1),\n",
       " ('쌀국수', 1),\n",
       " ('라면', 1),\n",
       " ('우동', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foodsGroup.groupByKey().mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupBy vs groupByKey\n",
    "- groupBy\n",
    "    - groupBy는 그룹핑할 때 키에 대한 정의를 개발자가 직접 해줘야 한다.\n",
    "    - groupBy(lambda x: x[0])과 같이 직접\n",
    "<br>\n",
    "</br>\n",
    "- groupByKey\n",
    "    - groupByKey 는 k-v RDD를 사용할 때 key가 알아서 그룹핑의 기준이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupByKey의 예시\n",
    "x = sc.parallelize([\n",
    "    (\"MATH\", 7), (\"MATH\", 2), (\"ENGLISH\", 7),\n",
    "    (\"SCIENCE\", 7), (\"ENGLISH\", 4), (\"ENGLISH\", 9),\n",
    "    (\"MATH\", 8), (\"MATH\", 3), (\"ENGLISH\", 4),\n",
    "    (\"SCIENCE\", 6), (\"SCIENCE\", 9), (\"SCIENCE\", 5)\n",
    "], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MATH', [7, 2, 8, 3]), ('ENGLISH', [7, 4, 9, 4]), ('SCIENCE', [7, 6, 9, 5])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기준을 정하지 않았지만 기준을 알아서 정의해준다.\n",
    "y = x.groupByKey()\n",
    "y.mapValues(list).collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduceByKey\n",
    "- KeyValueRDD.reduceByKey(task, numPartitions=None, partitionFuc=function portable_hash)\n",
    "- 주어지는 key를 기준으로 Group을 만들고 합쳐준다.(task대로)\n",
    "- Transformations 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜장면', 20), ('짬뽕', 10)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduceBykey 예시\n",
    "from operator import add\n",
    "\n",
    "rdd = sc.parallelize([\n",
    "    (\"짜장면\",15),\n",
    "    (\"짬뽕\",10),\n",
    "    (\"짜장면\",5)\n",
    "])\n",
    "\n",
    "rdd.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개념적으로는 groupByKey + reduce 이다.\n",
    "- groupbykey는 파티션이 나눠진 환경에서 reduce 진행.\n",
    "- reduce groupbykey 순으로 하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mapValues\n",
    "- KeyValueRDD.mapValues(<task>)\n",
    "- ``함수를 Value에만 적용합니다.``\n",
    "    - 파티션과 키는 그 위치에 그대로 있다.\n",
    "- Transformations 함수\n",
    "- key는 그대로 파티션 변경 되지 않는다. values 대해서만 수정가능\n",
    "- ``keyvalue RDD 에게는 mapValues가 좋다.(map보다는)``\n",
    "    - 이유 : ``파티션을 그대로 유지하기 때문에 map보다 훨씬 더 빠르다.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('하의', 3), ('상의', 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([\n",
    "    (\"하의\", [\"청바지\", \"반바지\", \"치마\"]),\n",
    "    (\"상의\", [\"니트\", \"반팔\", \"긴팔\", \"나시\"])\n",
    "])\n",
    "\n",
    "rdd.mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keys()\n",
    "- 모든 key를 가진 RDD를 생성한다.\n",
    "- 파티션을 유지하거나 키가 굉장히 많은 경우가 있기 때문에 transformations\n",
    "- `key의 개수`는 데이터의 개수를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[29] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformation\n",
    "rdd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하의', '상의']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect() 추가로 action\n",
    "rdd.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([\n",
    "    (\"MATH\", 7), (\"MATH\", 2), (\"ENGLISH\", 7),\n",
    "    (\"SCIENCE\", 7), (\"ENGLISH\", 4), (\"ENGLISH\", 9),\n",
    "    (\"MATH\", 8), (\"MATH\", 3), (\"ENGLISH\", 4),\n",
    "    (\"SCIENCE\", 6), (\"SCIENCE\", 9), (\"SCIENCE\", 5)\n",
    "], 3)\n",
    "\n",
    "print(x.keys().count()) # RDD\n",
    "# key의 개수는 데이터의 개수와 동일하다.\n",
    "# 수학 과학 영어 3개가 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# key의 종류의 개수\n",
    "print(x.keys().distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### countByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'하의': 1, '상의': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리스트가 하나씩\n",
    "rdd.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joins\n",
    "- inner Join 서로간에 존재하는 키만 합쳐준다.\n",
    "- outer Join 기준이 되는 한쪽에는 데이터가 있고, 다른 쪽에는 데이터가 없는 경우  \n",
    "    -설정한 기준에 따라서 기준에 맞는 데이터가 항상 남아있는다.  \n",
    "    -leftOuterJoin : 왼쪽에 있는 rdd가 기준이 된다.( 함수를 호출 하는 쪽이 기준이 된다.)  \n",
    "    -rightOuterJoin : 오른쪽에 있는 rdd가 기준이 된다. ( 함수의 매개변수로 들어가는 쪽이 기준이 된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([\n",
    "    (\"foo\", 1),\n",
    "    (\"goo\", 2),\n",
    "    (\"hoo\", 3)\n",
    "])\n",
    "\n",
    "rdd2 = sc.parallelize([\n",
    "    (\"foo\", 1),\n",
    "    (\"goo\", 2),\n",
    "    (\"goo\", 10),\n",
    "    (\"moo\", 6)\n",
    "])\n",
    "\n",
    "# join은 셔플링 현상일 일어날 수 밖에 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', (1, 1)), ('goo', (2, 2)), ('goo', (2, 10))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inner Join\n",
    "rdd1.join(rdd2).collect()\n",
    "# goo의 경우 앞쪽은 Rdd1 뒷쪽은 rdd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', (1, 1)), ('goo', (2, 2)), ('goo', (2, 10)), ('hoo', (3, None))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left Outer Join\n",
    "rdd1.leftOuterJoin(rdd2).collect()\n",
    "# left의 모든 것은 살아있다. 매칭되지 않는 moo는 삭제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', (1, 1)), ('moo', (None, 6)), ('goo', (2, 2)), ('goo', (2, 10))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Right Outer Join\n",
    "rdd1.rightOuterJoin(rdd2).collect()\n",
    "# right의 모든 것은 살아있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
