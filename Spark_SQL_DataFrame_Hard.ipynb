{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일이나 다른 데이터 소스로 부터 스파크 데이터 프레임 만드는 방법\n",
    "- spark.read.xxx(DataSource 경로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\apfhd\\\\SparkExam'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='c://Users//apfhd//SparkExam//data//titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas로 csv 불러오기 - 행렬 병렬 처리\n",
    "import pandas as pd\n",
    "titanic_pdf = pd.read_csv(f'{directory}',header=\"infer\")# header=\"infer\" 타입을 자동 유추해준다.\n",
    "titanic_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark로 csv 데이터 불러오기 - 병렬 분산 처리\n",
    "titanic_sdf=spark.read.csv(f'file:///{directory}',header=True, inferSchema=True) \n",
    "titanic_sdf\n",
    "# header=True : csv 기록된 컬럼 정보 포함\n",
    "# inferschema= True : 스키마 유추한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|        892|       0|     3|    Kelly, Mr. James|  male|34.5|    0|    0| 330911| 7.8292| null|       Q|\n",
      "|        893|       1|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0| 363272|    7.0| null|       S|\n",
      "|        894|       0|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0| 240276| 9.6875| null|       Q|\n",
      "|        895|       0|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0| 315154| 8.6625| null|       S|\n",
      "|        896|       1|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|3101298|12.2875| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrame 과 Spark DataFrame 의 주요 차이\n",
    "- pandas\n",
    "    - 싱글로드\n",
    "    - ``행렬 병렬처리``\n",
    "- spark \n",
    "    - 여러대의 클러스트\n",
    "    - ``병렬 분산처리`` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark DataFrame은 SQL 연산과 비슷한 연산자를 제공\n",
    "- spark_dataframe.select('컬럼명')\n",
    "- spark_dataframe.select('컬럼명').filter(...)\n",
    "    - filter : where절에 해당!\n",
    "- spark_dataframe.groupBy('컬럼명').count()\n",
    "- spark_dataframe.withColumns('컬럼명',...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Dataframe의 연산의 특징\n",
    "- Spark Dataframe의 연산은 대부분 새로운 Dataframe 객체를 반환하는 형태로 구성  \n",
    "- 특히 Dataframe 객체에 직접 수정을 허용하지 않는다.  \n",
    "    - Spark Dataframeeh RDD의 immutable 특징을 그대로 가져간다.  \n",
    "- spark dataframe은 RDD기반 이루어져있다.  \n",
    "==> ``spark dataframe 객체에 직접 수정을 허용하지 않는다``  \n",
    "* <u>pandas에서는 inplace를 통해 직접 수정이 가능하다.</u>  \n",
    "    <br>\n",
    "\n",
    "#### 비교  \n",
    "1. drop  \n",
    "    - pandas\n",
    "        - padnas_Dataframe.drop('컬럼명',axis=1,inplace=True) 호출하면 pandas_Dataframe 객체 자체에서 \"컬럼명'을 drop 시킨다.  \n",
    "    - ``Spark Dataframe``  \n",
    "        - Spark Dataframe_new =  Spark_Dataframe.drop('컬럼명')과 같이   \n",
    "        ``inplace 인자가 아예없음 ==> 새로운 변수로 받아줘야한다.``  \n",
    "        <br>\n",
    "2. 새로운 컬럼 만들기\n",
    "    - Pandas\n",
    "        - 특정 컬럼 값을 가져오거나, 새로운 컬럼을 만들기 위해서 사용했다.  \n",
    "        - pandas_dataframe['new_column'] = pandas_dataframe['column'] * 10  \n",
    "    - ``Spark Dataframe``  \n",
    "        - withColumns() 메소드를 활용  \n",
    "        - update 효과가 있다.  \n",
    "        - Spark Dataframe.withColumns('new_column',col('column')*10)  \n",
    "        - ``withColumns(), filters() 메소드에서 컬럼을 지정하기 위해서만 사용됨 -> [] 사용``  \n",
    "        <br>\n",
    "3. 컬럼에 접근하기  \n",
    "    - pandas  \n",
    "        - pandas_dataframe.drop(['컬럼1','컬럼2'])  \n",
    "    - ``Spark Dataframe``  \n",
    "        - Spark_Dataframe.drop('컬럼1','컬럼2')  \n",
    "        <br>\n",
    "4. Head 비교\n",
    "    - pandas  \n",
    "        - head : 데이터 프레임\n",
    "    - ``Spark ``\n",
    "        - head : Row object가 들어있는 list\n",
    "        - ``limit.show()`` : 데이터 프레임\n",
    "        <br>\n",
    "5. info 정보\n",
    "    - pandas\n",
    "        - 컬럼명, Data Type, ``not null`` 건수도 나온다.\n",
    "    - ``Spark``\n",
    "        - ``describe()`` 대신하나 컬럼명:Data Type 만 출력\n",
    "        - ``not null`` 을 위해 별도의 SQL 쿼리가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId=892, Survived=0, Pclass=3, Name='Kelly, Mr. James', Sex='male', Age=34.5, SibSp=0, Parch=0, Ticket='330911', Fare=7.8292, Cabin=None, Embarked='Q'),\n",
       " Row(PassengerId=893, Survived=1, Pclass=3, Name='Wilkes, Mrs. James (Ellen Needs)', Sex='female', Age=47.0, SibSp=1, Parch=0, Ticket='363272', Fare=7.0, Cabin=None, Embarked='S'),\n",
       " Row(PassengerId=894, Survived=0, Pclass=2, Name='Myles, Mr. Thomas Francis', Sex='male', Age=62.0, SibSp=0, Parch=0, Ticket='240276', Fare=9.6875, Cabin=None, Embarked='Q'),\n",
       " Row(PassengerId=895, Survived=0, Pclass=3, Name='Wirz, Mr. Albert', Sex='male', Age=27.0, SibSp=0, Parch=0, Ticket='315154', Fare=8.6625, Cabin=None, Embarked='S'),\n",
       " Row(PassengerId=896, Survived=1, Pclass=3, Name='Hirvonen, Mrs. Alexander (Helga E Lindqvist)', Sex='female', Age=22.0, SibSp=1, Parch=1, Ticket='3101298', Fare=12.2875, Cabin=None, Embarked='S')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_sdf.head(5) ## 이런모양은 쿼리를 칠수 없다. 데이터 프레임이 아니다. 데이터 프레임 함수를 칠수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 컬럼의 상세정보\n",
    "titanic_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0| 86|    0|    0|     0|   1|  327|       0|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Not null 카운트 확인하기\n",
    "from pyspark.sql.functions import count, isnan, when, col\n",
    "\n",
    "titanic_sdf.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in titanic_sdf.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark의 select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_01 = {'Name': ['상권', '동영','재준','성국', '성동'],\n",
    "           'Year': [2012, 2013, 2013, 2012, 2012],\n",
    "           'Gender': ['Male', 'Male', 'Male', 'Female', 'Male']\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pdf= pd.DataFrame(dict_01)\n",
    "data_sdf = spark.createDataFrame(data_pdf) #판다스 데이터 프레임을 스파크 데이터 프레임으로 만들기\n",
    "# data_sdf 테이블로 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>상권</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>동영</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>재준</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>성국</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>성동</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name  Year\n",
       "0   상권  2012\n",
       "1   동영  2013\n",
       "2   재준  2013\n",
       "3   성국  2012\n",
       "4   성동  2012"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pdf[['Name',\"Year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD 처럼 나온다. 원본데이터가 변형되었으니깐!\n",
    "data_sdf.select(\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼 속성으로 지정하여 select의 인자로 사용이 가능하다\n",
    "data_sdf.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|Name|Year|\n",
      "+----+----+\n",
      "|상권|2012|\n",
      "|동영|2013|\n",
      "|재준|2013|\n",
      "|성국|2012|\n",
      "|성동|2012|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 컬럼 속성으로 지정하여 select의 인자로 사용이 가능하다\n",
    "data_sdf.select(data_sdf.Name,data_sdf.Year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|Name|Year|\n",
      "+----+----+\n",
      "|상권|2012|\n",
      "|동영|2013|\n",
      "|재준|2013|\n",
      "|성국|2012|\n",
      "|성동|2012|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col # 명시적으로 컬럼명을 지정할 수 있는 함수\n",
    "# withcolumns 와 filter와 굉장히 많이 활용된다. 데이터를 가지고 와서 수정할 수 있게끔 한다.\n",
    "# col() 함수를 이용하며 명시적으로 컬럼명을 지정할 수 있음.\n",
    "data_sdf.select(col('Name'),col(\"Year\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper,lower,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+-------------+\n",
      "|Name|Year|Gender|upper(Gender)|\n",
      "+----+----+------+-------------+\n",
      "|상권|2012|  Male|         MALE|\n",
      "|동영|2013|  Male|         MALE|\n",
      "|재준|2013|  Male|         MALE|\n",
      "|성국|2012|Female|       FEMALE|\n",
      "|성동|2012|  Male|         MALE|\n",
      "+----+----+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select()에서 컬럼 데이터를 가공 후 생성 가능하다.\n",
    "data_sdf.select(\"*\",upper(col(\"Gender\"))).show() # select *, upper(Gender) from data_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----------+\n",
      "|Name|Year|Gender|Cap_Gender|\n",
      "+----+----+------+----------+\n",
      "|상권|2012|  Male|      MALE|\n",
      "|동영|2013|  Male|      MALE|\n",
      "|재준|2013|  Male|      MALE|\n",
      "|성국|2012|Female|    FEMALE|\n",
      "|성동|2012|  Male|      MALE|\n",
      "+----+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_sdf.select(\"*\",upper(col(\"Gender\")).alias(\"Cap_Gender\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark DataFrame의 filter 메소드 \n",
    "- `filter()` 는 `SQL WHERE 절`과 비슷 DataFrame 내의 특정 조건을 만족하는 레코드를 DataFrame으로 변환\n",
    "- filter() 내의 조건 컬럼은 컬럼 속성으로 지정 가능/ 조건문 자체는 ``SQL과 유사한 문자열로 지정``할 수 있다.\n",
    "- where() 메소드는 filter의 alias 함수이며, where 직관적인 동일성을 간주하기 위해 생성\n",
    "    - ``filter() == where()``\n",
    "- 복합조건 and or는 각각 &, | 로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_01 = {'Name': ['상권', '동영','재준','성국', '성동'],\n",
    "           'Year': [2012, 2013, 2013, 2012, 2012],\n",
    "           'Gender': ['Male', 'Male', 'Male', 'Female', 'Male']\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>상권</td>\n",
       "      <td>2012</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>동영</td>\n",
       "      <td>2013</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>재준</td>\n",
       "      <td>2013</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>성국</td>\n",
       "      <td>2012</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>성동</td>\n",
       "      <td>2012</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name  Year  Gender\n",
       "0   상권  2012    Male\n",
       "1   동영  2013    Male\n",
       "2   재준  2013    Male\n",
       "3   성국  2012  Female\n",
       "4   성동  2012    Male"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict -> pandas DataFrame 변환\n",
    "data_pdf=pd.DataFrame(dict_01)\n",
    "data_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Year: bigint, Gender: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas DataFrame -> Spark DataFrame\n",
    "data_sdf=spark.createDataFrame(data_pdf)\n",
    "data_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "condition should be string or Column",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18624\\2010778787.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_sdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m'상권'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 조건을 표현하기 위한 문자열이 들어가야한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, condition)\u001b[0m\n\u001b[0;32m   1733\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"condition should be string or Column\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1736\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: condition should be string or Column"
     ]
    }
   ],
   "source": [
    "data_sdf.filter('Name'== '상권') # 조건을 표현하기 위한 문자열이 들어가야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|Name|Year|Gender|\n",
      "+----+----+------+\n",
      "|상권|2012|  Male|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# () -> SQL의 where 절 처럼 사용해야한다.\n",
    "data_sdf.filter(\"Name='상권'\").show() # select * from data_sdf where Name='민호'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 복합 조건 and(&) or(|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|Name|Year|Gender|\n",
      "+----+----+------+\n",
      "|상권|2012|  Male|\n",
      "|동영|2013|  Male|\n",
      "|재준|2013|  Male|\n",
      "|성동|2012|  Male|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gender가 Male이고 Year가  2011년 이상인 사람의 모든 정보\n",
    "data_sdf.filter((data_sdf[\"Gender\"]==\"Male\")&(col(\"Year\")>2011)).show()\n",
    "# 복합 조건 시에 연산우선순위에 따라  ()로 다 묶어주는 것이 안전하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and or를 같이 사용하게될 때 ``and가 우선순위가 높다.``  \n",
    "- or and -> and 먼저 실행    \n",
    "- (or) and  -> or 먼저 실행(가로 덕분에)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자열 컬럼 like 조건 수행\n",
    "### ``특정 컬럼을 선택 -> 조건 수행``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|Name|Year|Gender|\n",
      "+----+----+------+\n",
      "|성국|2012|Female|\n",
      "|성동|2012|  Male|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문자열 컬럼 like 조건 수행\n",
    "# 특정 컬럼을 선택 -> 조건 수행\n",
    "data_sdf.filter(col(\"Name\").like(\"성%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|Name|Year|Gender|\n",
      "+----+----+------+\n",
      "|성국|2012|Female|\n",
      "|성동|2012|  Male|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_sdf.filter(\"Name like '성%'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|Name|Year|Gender|\n",
      "+----+----+------+\n",
      "|상권|2012|  Male|\n",
      "|동영|2013|  Male|\n",
      "|재준|2013|  Male|\n",
      "|성국|2012|Female|\n",
      "|성동|2012|  Male|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_sdf.filter(\"upper(Gender) like('%A%')\").show() # pyspark.sql.fuctions 에서 가져온 upper 함수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|Name|Year|Gender|\n",
      "+----+----+------+\n",
      "|상권|2012|  Male|\n",
      "|동영|2013|  Male|\n",
      "|재준|2013|  Male|\n",
      "|성국|2012|Female|\n",
      "|성동|2012|  Male|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "data_sdf.filter(upper(data_sdf[\"Gender\"]).like(\"%A%\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark DataFrame의 `orderBy()` 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orderBy에 컬럼명을 문자열로 지정하고 내림 차순 정렬\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|    Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\n",
      "|        911|       1|     3|\"Assaf Khalil, Mr...|female|45.0|    0|    0|      2696|  7.225| null|       C|\n",
      "|        941|       1|     3|\"Coutts, Mrs. Wil...|female|36.0|    0|    2|C.A. 37671|   15.9| null|       S|\n",
      "|        925|       1|     3|\"Johnston, Mrs. A...|female|null|    1|    2|W./C. 6607|  23.45| null|       S|\n",
      "|        927|       0|     3|\"Katavelas, Mr. V...|  male|18.5|    0|    0|      2682| 7.2292| null|       C|\n",
      "|       1141|       1|     3|\"Khalil, Mrs. Bet...|female|null|    1|    0|      2660|14.4542| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"orderBy에 컬럼명을 문자열로 지정하고 내림 차순 정렬\")\n",
    "# titanic_sdf.orderBy(\"Name\",ascending=False).show()\n",
    "\n",
    "# 직접 컬럼을 선택해서 내림 차순 정렬\n",
    "# 1번 방식)titanic_sdf.orderBy(titanic_sdf[\"Name\"],ascending=True).show()\n",
    "# 2번 방식)titanic_sdf.orderBy(titanic_sdf.Name, ascending=True).show()\n",
    "# 3번 방식)\n",
    "titanic_sdf.orderBy(col(\"Name\"), ascending=True).show(5) #  이게 제일 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+--------+-----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|  Ticket| Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+--------+-----+-----+--------+\n",
      "|       1084|       0|     3|van Billiard, Mas...|male|11.5|    1|    1|A/5. 851| 14.5| null|       S|\n",
      "|       1236|       0|     3|van Billiard, Mas...|male|null|    1|    1|A/5. 851| 14.5| null|       S|\n",
      "|       1152|       0|     3|de Messemaeker, M...|male|36.5|    1|    0|  345572| 17.4| null|       S|\n",
      "|       1063|       0|     3| Zakarian, Mr. Ortin|male|27.0|    0|    0|    2670|7.225| null|       C|\n",
      "|       1028|       0|     3|Zakarian, Mr. Map...|male|26.5|    0|    0|    2656|7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+--------+-----+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_sdf.orderBy(\"Pclass\",\"Name\",ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|  Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-------+--------+\n",
      "|       1263|       1|     1|Wilson, Miss. Hel...|female|31.0|    0|    0|   16966|  134.5|E39 E41|       C|\n",
      "|        915|       0|     1|Williams, Mr. Ric...|  male|21.0|    0|    1|PC 17597|61.3792|   null|       C|\n",
      "|       1123|       1|     1|Willard, Miss. Co...|female|21.0|    0|    0|  113795|  26.55|   null|       S|\n",
      "|       1110|       1|     1|Widener, Mrs. Geo...|female|50.0|    1|    1|  113503|  211.5|    C80|       C|\n",
      "|       1299|       0|     1|Widener, Mr. Geor...|  male|50.0|    1|    1|  113503|  211.5|    C80|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_sdf.orderBy(col(\"Pclass\").asc(),col(\"Name\").desc()).show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|Pclass|                name|\n",
      "+------+--------------------+\n",
      "|     1|Wilson, Miss. Hel...|\n",
      "|     1|Williams, Mr. Ric...|\n",
      "|     1|Willard, Miss. Co...|\n",
      "|     1|Widener, Mrs. Geo...|\n",
      "|     1|Widener, Mr. Geor...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 추출하고 (Pclass, Name을 select)하고 정렬\n",
    "# select Pclass,Name from titanic_sdf order by Pclass asc, Name desc \n",
    "# 데이터 선택하고 내가 필요한 부분만 뽑아오는 방식\n",
    "titanic_sdf.select(col(\"Pclass\"),col(\"name\")).orderBy(col(\"Pclass\").asc(),col(\"name\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|Pclass|                Name|\n",
      "+------+--------------------+\n",
      "|     1|Wilson, Miss. Hel...|\n",
      "|     1|Williams, Mr. Ric...|\n",
      "|     1|Willard, Miss. Co...|\n",
      "|     1|Widener, Mrs. Geo...|\n",
      "|     1|Widener, Mr. Geor...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 정렬하고 추출 - 대량의 데이터라면 여기가 유리하다. 셔플링작업을 최소화 할 수 있다.\n",
    "# select Pclass, Name from (select * from titanic_sdf order by Pclass asc,Name desc)\n",
    "titanic_sdf.orderBy(col(\"Pclass\").asc(),col(\"Name\").desc()).select(col(\"Pclass\"),col(\"Name\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark DataFrame의 groupby()\n",
    "    - pandas\n",
    "        - groupby(by='컬럼명') -> DataFrameGroupBy 객체가 반환 + aggregation\n",
    "    - Spark\n",
    "        - groupby(by='컬럼명') -> GroupedData 객체가 반환 + aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>98</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>146</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>217</td>\n",
       "      <td>4</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId  Survived  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
       "Pclass                                                                      \n",
       "1               107       107   107  107   98    107    107     107   107   \n",
       "2                93        93    93   93   88     93     93      93    93   \n",
       "3               218       218   218  218  146    218    218     218   217   \n",
       "\n",
       "        Cabin  Embarked  \n",
       "Pclass                   \n",
       "1          80       107  \n",
       "2           7        93  \n",
       "3           4       218  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pdf_groupby=titanic_pdf.groupby(by=\"Pclass\")\n",
    "titanic_pdf_groupby.count() # 판다스에서는 count()에 값을 지정하지 않아도 각 컬럼별 개수가 나오지만 Spark는 특정 컬럼 지정해줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>51</td>\n",
       "      <td>94.280297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.0</td>\n",
       "      <td>35</td>\n",
       "      <td>22.202104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.5</td>\n",
       "      <td>101</td>\n",
       "      <td>12.459678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  SibSp       Fare\n",
       "Pclass                        \n",
       "1       76.0     51  94.280297\n",
       "2       63.0     35  22.202104\n",
       "3       60.5    101  12.459678"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 컬럼에 대한 다른 집계\n",
    "agg_format={\n",
    "    \"Age\":\"max\",\n",
    "    \"SibSp\":\"sum\",\n",
    "    \"Fare\":'mean'\n",
    "}\n",
    "\n",
    "titanic_pdf_groupby.agg(agg_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    218\n",
       "1    107\n",
       "2     93\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas\n",
    "# value_counts : pandas에서 series 안쪽 값 구하기\n",
    "titanic_pdf[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  107|\n",
      "|     3|  218|\n",
      "|     2|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark\n",
    "titanic_sdf.groupby(\"Pclass\").count().show()\n",
    "# GroupedData 객체에 count()외에 min(),Max(),avg(),sum() 등 다양한 aggregation 메소드를 호출하여\n",
    "# group by, aggregation 결과 DataFrame이 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|  Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+------+-----+--------+\n",
      "|        898|       1|     3|Connolly, Miss. Kate|female|30.0|    0|    0|          330972|7.6292| null|       Q|\n",
      "|        910|       1|     3|Ilmakangas, Miss....|female|27.0|    1|    0|STON/O2. 3101270| 7.925| null|       S|\n",
      "|        900|       1|     3|Abrahim, Mrs. Jos...|female|18.0|    0|    0|            2657|7.2292| null|       C|\n",
      "|        893|       1|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|          363272|   7.0| null|       S|\n",
      "|        901|       0|     3|Davies, Mr. John ...|  male|21.0|    2|    0|       A/4 48871| 24.15| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pclass 카운트 내림 차순 정렬\n",
    "titanic_sdf.orderBy(col(\"Pclass\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     3|  218|\n",
      "|     1|  107|\n",
      "|     2|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pclass별로 카운트 내림 차순 정렬\n",
    "titanic_sdf.groupBy(\"Pclass\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupedData에서 aggregation 메소드를 호출 할때는 ``오직 문자열 컬럼명만`` 가능   \n",
    "- ex) ``max(\"Age\") -> ok`` / ``max(col(\"Age\")) -> Error``\n",
    "- (컬럼형 인자는 오류 발생)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|Pclass|max(Age)|\n",
      "+------+--------+\n",
      "|     1|    76.0|\n",
      "|     3|    60.5|\n",
      "|     2|    63.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# age 만 확인하기\n",
    "titanic_sdf.groupBy(\"Pclass\").max(\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Column is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18624\\2491348710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# GroupedData에서 aggregation 메소드를 호출 할때는 오직 문자열 컬럼명만 가능 (컬럼형 인자는 오류 발생)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtitanic_sdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Age\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\group.py\u001b[0m in \u001b[0;36m_api\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m_to_seq\u001b[1;34m(sc, cols, converter)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0margs_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                         \u001b[0mtemp_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, object, gateway_client)\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mjava_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0margs_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                         \u001b[0mtemp_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.2-src.zip\\py4j\\java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, object, gateway_client)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mArrayList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJavaClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"java.util.ArrayList\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m             \u001b[0mjava_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Column is not iterable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[1;31m# string methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Column is not iterable"
     ]
    }
   ],
   "source": [
    "# age 만 확인하기\n",
    "titanic_sdf.groupBy(\"Pclass\").max(col(\"Age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+\n",
      "|Pclass|Max_age|  Total|\n",
      "+------+-------+-------+\n",
      "|     1|   76.0| 4010.0|\n",
      "|     3|   60.5|3508.08|\n",
      "|     2|   63.0|2532.42|\n",
      "+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여러개 agg 할 경우 agg(개별 agg함수 작성)\n",
    "titanic_sdf.groupBy(\"Pclass\").agg(max(\"Age\").alias(\"Max_age\"),sum(\"Age\").alias(\"Total\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
